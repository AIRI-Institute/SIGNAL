{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24453d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import natasha\n",
    "from scipy import  stats\n",
    "from collections import Counter\n",
    "import pymorphy2\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import itertools\n",
    "import json\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "    Doc\n",
    ")\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "tqdm.pandas()\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "m = Mystem()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e029e-1343-4a7a-865d-dc99f6d159d6",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "\n",
    "1. Open original dataset \"src/original_dataset.csv\"\n",
    "2. Find grammatical base of each sentence using 'find_base' function -> \"result/congruent_sentences.csv\"\n",
    "3. Manually correct the base sentence and save it in the column \"sent_corrected\" -> \"result/congruent_sentences_corrected.csv\"\n",
    "4. Find syntactic structure of the sentences and words' frequeincies and length in the \"sent_corrected\" column using \"find_struct\" function -> \"congruent_sentences_corrected_marked.csv\"\n",
    "5. For missing values (words' frequencies, gender) in \"result/congruent_sentences_corrected_marked.csv\" add values manually or using find_ipm_in_ruscorpora function\n",
    "6. Manually select appropriate sentences in \"result/congruent_sentences_corrected_marked.csv\" (add column \"selected\") and split dataset in two groups: \"to_evaluate\" (experimental stimuli) and \"control\" (control stimuli) -> \"result/congruent_sentences_corrected_marked+.csv\"\n",
    "7. Estimate the distribution of 'length' and 'IPM' stimuli parameters between sentences with different syntactic structure\n",
    "8. Generate incongruent sentences based on selected stimuli -> \"result/incongruent_sentences_toloka.csv\"\n",
    "9. Evaluate sentences via TOLOKA -> \"result/toloka_evaluation.csv\"\n",
    "10. Based on TOLOKA evaluation results, select only those sentences which error types were correctly assessed by participants for each of four error types -> \"result/final_candidates.csv\"\n",
    "11. Manually check and select most appropriate stimuli for the corpus ->  \"result/FINAL_STIMULI.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc58b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_base(text: str):\n",
    "    \"\"\"\n",
    "    Find grammatical base of the sentence (Subject + Verb + Object)\n",
    "    and checks whether it is complete (contains three arguments)\n",
    "    :param text: text of the sentence to check\n",
    "    :return: (text of grammatical base (str), mark whether base is complete (bool))\n",
    "    \"\"\"\n",
    "    res = {'nsubj': '',\n",
    "           'root': '',\n",
    "          'dobj': ''}\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    doc.parse_syntax(syntax_parser) \n",
    "    tokens = {tok.id: tok for tok in doc.tokens}\n",
    "    ok = 0\n",
    "    for tok in doc.tokens:\n",
    "        if tok.rel == 'root':\n",
    "            res['root'] = tok.text\n",
    "            ok += tok.pos == 'VERB'\n",
    "        elif tok.rel == 'nsubj' and tokens[tok.head_id].rel == 'root':\n",
    "            res['nsubj'] = tok.text\n",
    "            ok += tok.pos == 'NOUN'\n",
    "        elif tok.rel == 'obj' and tokens[tok.head_id].rel == 'root':\n",
    "            res['dobj'] = tok.text\n",
    "            ok += tok.pos == 'NOUN'        \n",
    "    return (' '.join(res.values()).strip().capitalize(), ok == 3)\n",
    "\n",
    "def find_struct(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Fuction to find syntactic structure of the input sentence\n",
    "    :param text: text of the sentence to check\n",
    "    :return: syntactic structure of the sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    doc.parse_syntax(syntax_parser) \n",
    "    tokens = {tok.id: tok for tok in doc.tokens}\n",
    "    ok = 0\n",
    "    if (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'NOUN' and \n",
    "        len(doc.tokens) == 3):\n",
    "        return 'Subject - Verb - Object'\n",
    "    elif len(doc.tokens) == 3:\n",
    "        return 'check me'\n",
    "    elif (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'NOUN' and \n",
    "        doc.tokens[3].pos == 'NOUN' and \n",
    "        doc.tokens[3].feats['Case'] == 'Gen' and \n",
    "        len(doc.tokens) == 4):\n",
    "        return 'Subject - Verb - Object - Gen'\n",
    "    elif (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'ADJ' and \n",
    "        doc.tokens[3].pos == 'NOUN' and \n",
    "        len(doc.tokens) == 4):\n",
    "        return 'Subject - Verb - Adj - Object'\n",
    "    elif (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'NOUN' and \n",
    "        doc.tokens[3].pos == 'ADP' and \n",
    "        doc.tokens[4].pos == 'NOUN' and \n",
    "        len(doc.tokens) == 5):\n",
    "        return 'Subject - Verb - Object - PP'\n",
    "    \n",
    "def count_syllables(word):\n",
    "    \"\"\"\n",
    "    Function to count syllables in the word\n",
    "    :param word: word\n",
    "    :return: length of word in syllables\n",
    "    \"\"\"\n",
    "    if not isinstance(word, str):\n",
    "        return\n",
    "    counter = 0\n",
    "    vowels = 'аеиюэоыуея'\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Function to get lemma (initial form) of the word\n",
    "    :param word: word\n",
    "    :return: lemma (initial form) of the word\n",
    "    \"\"\"\n",
    "    if not isinstance(word, str):\n",
    "        return\n",
    "    return morph.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0687050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table(df: pd.DataFrame, column: str, df_name=None, sheet=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function to find sentence syntactic structure and words' length in syllables\n",
    "    :param df: pd.DataFrame\n",
    "    :param df_name: path to df\n",
    "    :param sheet: sheet_name\n",
    "    :param column: column name\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    ruscorpora_frequencies = pd.read_csv('src/ruscorpora_frequencies.csv')\n",
    "\n",
    "    frequencies = {word: ipm for word, ipm in zip(ruscorpora_frequencies['lex'],\n",
    "                                                  ruscorpora_frequencies['ipm'])}\n",
    "    \n",
    "    if df_name is not None:\n",
    "        df = pd.read_excel(df_name, sheet_name=sheet)\n",
    "    df['length'] = df[column].apply(lambda x: len(x.split(' ')))\n",
    "    df['structure'] = df[column].apply(find_struct)\n",
    "    df['words'] = df[column].apply(lambda x: x.split())\n",
    "\n",
    "    subjects = []\n",
    "    verbs = []\n",
    "    objectives = []\n",
    "    genitives = []\n",
    "    adjectives = []\n",
    "    prepositions = []\n",
    "    objectives2 = []\n",
    "\n",
    "    for sent, struct in zip(df['words'], df['structure']):\n",
    "        subjects.append(sent[0].lower())\n",
    "        verbs.append(sent[1])\n",
    "        obj = sent[3] if struct == 'Subject - Verb - Adj - Object' else sent[2]\n",
    "        objectives.append(obj)\n",
    "        gen = sent[3] if struct == 'Subject - Verb - Object - Gen' else None\n",
    "        genitives.append(gen)\n",
    "        adj = sent[2] if struct == 'Subject - Verb - Adj - Object' else None\n",
    "        adjectives.append(adj)\n",
    "        prep = sent[3] if struct == 'Subject - Verb - Object - PP' else None\n",
    "        prepositions.append(prep)\n",
    "        if struct == 'Subject - Verb - Object - PP':\n",
    "            obj2 = sent[4] \n",
    "        else:\n",
    "            obj2 = None\n",
    "        objectives2.append(obj2)\n",
    "\n",
    "\n",
    "    df['subject'] = subjects\n",
    "    df['verb'] = verbs\n",
    "    df['object'] = objectives\n",
    "    df['gen'] = genitives\n",
    "    df['adj'] = adjectives\n",
    "    df['preposition'] = prepositions\n",
    "    df['object2'] = objectives2\n",
    "\n",
    "    for column in ['subject', 'verb', 'object', 'gen', 'adj',\n",
    "                   'preposition', 'object2']:\n",
    "        df[f'{column}_length'] = df[column].map(count_syllables)\n",
    "        df[f'{column}_lemma'] = df[column].map(lambda x: normalize(x))\n",
    "        df[f'{column}_ipm'] = df[f'{column}_lemma'].apply(lambda x: frequencies.get(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5508e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ipm_in_ruscorpora(df, target_columns):\n",
    "    \"\"\"\n",
    "    Function to collect words' IPM and gender in ruscorpora.ru\n",
    "    \"\"\"\n",
    "\n",
    "    def find_ipm(word, driver):\n",
    "        try:\n",
    "            driver.get(f'https://ruscorpora.ru/explore?req={word}')  \n",
    "            time.sleep(0.5)\n",
    "            driver.find_elements(By.CLASS_NAME, 'link--accent')[1].click()\n",
    "            time.sleep(0.5)\n",
    "            button = [button for button in driver.find_elements(By.TAG_NAME, 'button')\n",
    "                     if button.text == 'Частотность'][0]\n",
    "            button.click()\n",
    "            time.sleep(0.5)\n",
    "            return float(driver.find_element(By.XPATH, '/html/body/div[4]/main/div/div[3]/div[1]/div[1]/div[2]/div/table/tbody/tr/td[5]/span').text.replace(',', '.')) \n",
    "        except Exception as e:\n",
    "            print(e, word)\n",
    "            return \n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    for column in target_columns: \n",
    "        words += df[f'{column} lemma'].tolist()\n",
    "\n",
    "    words_ipm_dict = {w: find_ipm(w, driver) for w in tqdm(set(words))}\n",
    "\n",
    "    for col in ['Subject', 'Object', 'Object 2',\n",
    "                'Verb', 'Object', 'Gen', 'Adj',\n",
    "                'Object 2']:\n",
    "        df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
    "        df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
    "            lambda x: morph.parse(x)[0].tag.gender if isinstance(x, str) else None)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62191f9-9b5f-4f02-80bd-d3cda7c0d0bd",
   "metadata": {},
   "source": [
    "# Evaluate syntactic structures of original sentences\n",
    "\n",
    "- Open original dataset \"src/original_dataset.csv\"\n",
    "- Find grammatical base of each sentence using 'find_base' function -> \"result/congruent_sentences.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e62cb80-df11-4f9d-944a-608074d331e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congruent</th>\n",
       "      <th>base_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Компания начала внутреннее расследование произ...</td>\n",
       "      <td>Компания начала расследование</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Пара имеет ныне трёх дочерей .</td>\n",
       "      <td>Пара имеет дочерей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Тогда пираты похитили четырех человек .</td>\n",
       "      <td>Пираты похитили человек</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>В ассоциации организации комментировать ситуац...</td>\n",
       "      <td>Отказались ситуацию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Многие тысячи покинули места погромов .</td>\n",
       "      <td>Тысячи покинули места</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            congruent  \\\n",
       "0   Компания начала внутреннее расследование произ...   \n",
       "4                      Пара имеет ныне трёх дочерей .   \n",
       "8             Тогда пираты похитили четырех человек .   \n",
       "14  В ассоциации организации комментировать ситуац...   \n",
       "15            Многие тысячи покинули места погромов .   \n",
       "\n",
       "                        base_sent  \n",
       "0   Компания начала расследование  \n",
       "4              Пара имеет дочерей  \n",
       "8         Пираты похитили человек  \n",
       "14            Отказались ситуацию  \n",
       "15          Тысячи покинули места  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists('result'):\n",
    "    os.mkdir('result')\n",
    "    \n",
    "df = pd.read_csv('src/original_dataset.csv')\n",
    "df['base'] = df['congruent'].apply(find_base)\n",
    "df[['base_sent', 'criterion']] = pd.DataFrame(df.base.tolist(), index = df.index)\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['criterion']][['congruent', 'base_sent']]\n",
    "df.to_csv('result/congruent_sentences.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643186ba-c46b-4928-8ae0-0bfa0e28b30f",
   "metadata": {},
   "source": [
    "- Manually correct the base sentence and save it in the column \"sent_corrected\" -> \"result/congruent_sentences_corrected.csv\"\n",
    "- Find syntactic structure of the sentences and words' frequeincies and length in the \"sent_corrected\" column using \"find_struct\" function -> \"congruent_sentences_corrected_marked.csv\"\n",
    "- For missing values (words' frequencies, gender) in \"result/congruent_sentences_corrected_marked.csv\" add values manually or using find_ipm_in_ruscorpora function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3243fe2b-3879-4048-a019-791eed80b5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congruent</th>\n",
       "      <th>base_sent</th>\n",
       "      <th>sent_corrected</th>\n",
       "      <th>length</th>\n",
       "      <th>structure</th>\n",
       "      <th>words</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>gen</th>\n",
       "      <th>...</th>\n",
       "      <th>gen_ipm</th>\n",
       "      <th>adj_length</th>\n",
       "      <th>adj_lemma</th>\n",
       "      <th>adj_ipm</th>\n",
       "      <th>preposition_length</th>\n",
       "      <th>preposition_lemma</th>\n",
       "      <th>preposition_ipm</th>\n",
       "      <th>object2_length</th>\n",
       "      <th>object2_lemma</th>\n",
       "      <th>object2_ipm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Авиакомпания официально подтвердила факт круше...</td>\n",
       "      <td>Авиакомпания подтвердила факт</td>\n",
       "      <td>Авиакомпания подтвердила факт крушения</td>\n",
       "      <td>4</td>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>[Авиакомпания, подтвердила, факт, крушения]</td>\n",
       "      <td>авиакомпания</td>\n",
       "      <td>подтвердила</td>\n",
       "      <td>факт</td>\n",
       "      <td>крушения</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Также массовую дезинфекцию проходят городские ...</td>\n",
       "      <td>Автобусы проходят дезинфекцию</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>4</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>[Автобусы, проходят, массовую, дезинфекцию]</td>\n",
       "      <td>автобусы</td>\n",
       "      <td>проходят</td>\n",
       "      <td>дезинфекцию</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В результате автомобиль получил технические по...</td>\n",
       "      <td>Автомобиль получил повреждения</td>\n",
       "      <td>Автомобиль получил технические повреждения</td>\n",
       "      <td>4</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>[Автомобиль, получил, технические, повреждения]</td>\n",
       "      <td>автомобиль</td>\n",
       "      <td>получил</td>\n",
       "      <td>повреждения</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>технический</td>\n",
       "      <td>73.606628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Однако сами авторы выдвинули более осторожное ...</td>\n",
       "      <td>Авторы выдвинули предположение</td>\n",
       "      <td>Авторы выдвинули осторожное предположение</td>\n",
       "      <td>4</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>[Авторы, выдвинули, осторожное, предположение]</td>\n",
       "      <td>авторы</td>\n",
       "      <td>выдвинули</td>\n",
       "      <td>предположение</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>осторожный</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Авторы письма выразили возмущение перебоями ра...</td>\n",
       "      <td>Авторы выразили возмущение</td>\n",
       "      <td>Авторы выразили возмущение</td>\n",
       "      <td>3</td>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>[Авторы, выразили, возмущение]</td>\n",
       "      <td>авторы</td>\n",
       "      <td>выразили</td>\n",
       "      <td>возмущение</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           congruent  \\\n",
       "2  Авиакомпания официально подтвердила факт круше...   \n",
       "3  Также массовую дезинфекцию проходят городские ...   \n",
       "4  В результате автомобиль получил технические по...   \n",
       "5  Однако сами авторы выдвинули более осторожное ...   \n",
       "6  Авторы письма выразили возмущение перебоями ра...   \n",
       "\n",
       "                        base_sent                              sent_corrected  \\\n",
       "2   Авиакомпания подтвердила факт      Авиакомпания подтвердила факт крушения   \n",
       "3   Автобусы проходят дезинфекцию      Автобусы проходят массовую дезинфекцию   \n",
       "4  Автомобиль получил повреждения  Автомобиль получил технические повреждения   \n",
       "5  Авторы выдвинули предположение   Авторы выдвинули осторожное предположение   \n",
       "6      Авторы выразили возмущение                  Авторы выразили возмущение   \n",
       "\n",
       "   length                      structure  \\\n",
       "2       4  Subject - Verb - Object - Gen   \n",
       "3       4  Subject - Verb - Adj - Object   \n",
       "4       4  Subject - Verb - Adj - Object   \n",
       "5       4  Subject - Verb - Adj - Object   \n",
       "6       3        Subject - Verb - Object   \n",
       "\n",
       "                                             words       subject         verb  \\\n",
       "2      [Авиакомпания, подтвердила, факт, крушения]  авиакомпания  подтвердила   \n",
       "3      [Автобусы, проходят, массовую, дезинфекцию]      автобусы     проходят   \n",
       "4  [Автомобиль, получил, технические, повреждения]    автомобиль      получил   \n",
       "5   [Авторы, выдвинули, осторожное, предположение]        авторы    выдвинули   \n",
       "6                   [Авторы, выразили, возмущение]        авторы     выразили   \n",
       "\n",
       "          object       gen  ... gen_ipm adj_length    adj_lemma    adj_ipm  \\\n",
       "2           факт  крушения  ...     NaN        NaN         None        NaN   \n",
       "3    дезинфекцию      None  ...     NaN        4.0     массовый  50.834561   \n",
       "4    повреждения      None  ...     NaN        5.0  технический  73.606628   \n",
       "5  предположение      None  ...     NaN        5.0   осторожный        NaN   \n",
       "6     возмущение      None  ...     NaN        NaN         None        NaN   \n",
       "\n",
       "  preposition_length  preposition_lemma  preposition_ipm object2_length  \\\n",
       "2                NaN               None             None            NaN   \n",
       "3                NaN               None             None            NaN   \n",
       "4                NaN               None             None            NaN   \n",
       "5                NaN               None             None            NaN   \n",
       "6                NaN               None             None            NaN   \n",
       "\n",
       "   object2_lemma  object2_ipm  \n",
       "2           None          NaN  \n",
       "3           None          NaN  \n",
       "4           None          NaN  \n",
       "5           None          NaN  \n",
       "6           None          NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('result/congruent_sentences_corrected.csv')\n",
    "df_marked = process_table(df, 'sent_corrected')\n",
    "df_marked = df_marked[df_marked['structure'].notnull()]\n",
    "df_marked.to_csv('result/congruent_sentences_corrected_marked.csv')\n",
    "df_marked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de15d75e-abb5-44de-afa4-c2e6942b2616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "structure\n",
       "Subject - Verb - Object          297\n",
       "Subject - Verb - Adj - Object    184\n",
       "Subject - Verb - Object - Gen    149\n",
       "check me                          18\n",
       "Subject - Verb - Object - PP      14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_marked.value_counts('structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a28fc3-09e8-4e61-8467-7bc697c8d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_columns = ['Subject', 'Object','Verb', 'Gen', 'Adj']\n",
    "# df_processed =  find_ipm_in_ruscorpora(df_marked, target_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc894422",
   "metadata": {},
   "source": [
    "# Stimuli evaluation and selection\n",
    "\n",
    "- Manually select appropriate sentences in \"result/congruent_sentences_corrected_marked.csv\" (add column \"selected\") and split dataset in two groups: \"to_evaluate\" (experimental stimuli) and \"control\" (control stimuli) -> \"result/congruent_sentences_corrected_marked+.csv\"\n",
    "- Estimate the distribution of 'length' and 'IPM' stimuli parameters between sentences with different syntactic structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b41d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "verb\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "object\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('result/congruent_sentences_corrected_marked+.csv')\n",
    "df = df[(df['task_type'] == 'to_evaluate') & (\n",
    "    df['selected'] == 1) & (\n",
    "    df['structure'].isin(['Subject - Verb - Object',\n",
    "                          'Subject - Verb - Object - Gen',\n",
    "                          'Subject - Verb - Adj - Object']))]\n",
    "\n",
    "for item in ['subject', 'verb', 'object']:\n",
    "    print(item)\n",
    "    df[f'{item}_ipm'] = df[f'{item}_ipm'].dropna()\n",
    "    for comb in itertools.combinations(df['structure'].unique(), 2):\n",
    "        print(comb)\n",
    "        print('ipm', \n",
    "              stats.ttest_ind(df[df['structure'] == comb[0]][f'{item}_ipm'].dropna().tolist(),\n",
    "                              df[df['structure'] == comb[1]][f'{item}_ipm'].dropna().tolist()).pvalue > 0.05)\n",
    "        print('length', \n",
    "              stats.ttest_ind(df[df['structure'] == comb[0]][f'{item}_length'].dropna().tolist(),\n",
    "                              df[df['structure'] == comb[1]][f'{item}_length']).pvalue > 0.05)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5118a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "structure\n",
       "Subject - Verb - Adj - Object    75\n",
       "Subject - Verb - Object          75\n",
       "Subject - Verb - Object - Gen    75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['structure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f09c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8337370955973877)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(df[df['structure'] == 'Subject - Verb - Adj - Object'][f'adj_ipm'].dropna().tolist(),\n",
    "                df[df['structure'] == 'Subject - Verb - Object - Gen'][f'gen_ipm'].dropna().tolist()).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695196d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject\n",
      "ipm False\n",
      "length False\n",
      "\n",
      "verb\n",
      "ipm False\n",
      "length False\n",
      "\n",
      "object\n",
      "ipm False\n",
      "length False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_control = df[df['task_type'] == 'control']\n",
    "df_evaluate = df[df['task_type'] == 'to_evaluate']\n",
    "\n",
    "for item in ['subject', 'verb', 'object']:\n",
    "    print(item)\n",
    "    print('ipm', \n",
    "              stats.ttest_ind(df_evaluate[f'{item}_ipm'].dropna().tolist(),\n",
    "                              df_control[f'{item}_ipm'].dropna().tolist()).pvalue > 0.05)\n",
    "    print('length', \n",
    "              stats.ttest_ind(df_evaluate[f'{item}_length'].dropna().tolist(),\n",
    "                              df_control[f'{item}_length']).pvalue > 0.05)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692cd75-0a8f-4ed5-bcee-4c6c57a057d6",
   "metadata": {},
   "source": [
    "## Stimuli selection based on Toloka assessment\n",
    "\n",
    "- Generate incongruent sentences based on selected stimuli -> \"result/incongruent_sentences_toloka.csv\"\n",
    "- Evaluate sentences via TOLOKA -> \"result/toloka_evaluation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa4a85e-7e39-4127-847e-abe61f4c5b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>congruent</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>semantics_grammar</th>\n",
       "      <th>semantics</th>\n",
       "      <th>grammar</th>\n",
       "      <th>no</th>\n",
       "      <th>unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>gen_length</th>\n",
       "      <th>gen_lemma</th>\n",
       "      <th>gen_ipm</th>\n",
       "      <th>gen_gender</th>\n",
       "      <th>adj_length</th>\n",
       "      <th>adj_lemma</th>\n",
       "      <th>adj_ipm</th>\n",
       "      <th>adj_gender</th>\n",
       "      <th>task_type</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцией</td>\n",
       "      <td>grammar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую фортуну</td>\n",
       "      <td>semantics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую фортуной</td>\n",
       "      <td>semantics_grammar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Авторы получали подарки</td>\n",
       "      <td>2</td>\n",
       "      <td>Авторы получали районах</td>\n",
       "      <td>semantics_grammar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                               congruent  position  \\\n",
       "0            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "1            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "2            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "3            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "4            2                 Авторы получали подарки         2   \n",
       "\n",
       "                                  sentence             target  \\\n",
       "0  Автобусы проходят массовую дезинфекцией            grammar   \n",
       "1       Автобусы проходят массовую фортуну          semantics   \n",
       "2      Автобусы проходят массовую фортуной  semantics_grammar   \n",
       "3   Автобусы проходят массовую дезинфекцию                 no   \n",
       "4                  Авторы получали районах  semantics_grammar   \n",
       "\n",
       "   semantics_grammar  semantics  grammar        no  unknown  ... gen_length  \\\n",
       "0                NaN        NaN      1.0       NaN      NaN  ...        NaN   \n",
       "1                NaN   1.000000      NaN       NaN      NaN  ...        NaN   \n",
       "2                1.0        NaN      NaN       NaN      NaN  ...        NaN   \n",
       "3                NaN   0.166667      NaN  0.833333      NaN  ...        NaN   \n",
       "4                1.0        NaN      NaN       NaN      NaN  ...        NaN   \n",
       "\n",
       "   gen_lemma gen_ipm  gen_gender adj_length adj_lemma    adj_ipm adj_gender  \\\n",
       "0        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "1        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "2        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "3        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "4        NaN    0.02         NaN        NaN       NaN   0.020000        NaN   \n",
       "\n",
       "     task_type selected  \n",
       "0  to_evaluate        1  \n",
       "1  to_evaluate        1  \n",
       "2  to_evaluate        1  \n",
       "3  to_evaluate        1  \n",
       "4  to_evaluate        1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incongruent_stimuli = pd.read_csv('result/incongruent_sentences_toloka.csv')\n",
    "evaluation_res = pd.read_csv('result/toloka_evaluation.csv')\n",
    "stimuli_properties = pd.read_csv('result/congruent_sentences_corrected_marked+.csv')\n",
    "\n",
    "df = pd.merge(incongruent_stimuli, evaluation_res, on=['sentence'])\n",
    "df = pd.merge(df, stimuli_properties, on=['sentence_id', 'congruent', 'position'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f67bb6-124b-4e23-8147-76bd22030cea",
   "metadata": {},
   "source": [
    " - Based on TOLOKA evaluation results, select only those sentences which error types were correctly assessed by participants for each of four error types -> \"result/final_candidates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "904079df-181c-4cee-af0b-76fdf052b5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>congruent</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>semantics_grammar</th>\n",
       "      <th>semantics</th>\n",
       "      <th>grammar</th>\n",
       "      <th>no</th>\n",
       "      <th>unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>gen_length</th>\n",
       "      <th>gen_lemma</th>\n",
       "      <th>gen_ipm</th>\n",
       "      <th>gen_gender</th>\n",
       "      <th>adj_length</th>\n",
       "      <th>adj_lemma</th>\n",
       "      <th>adj_ipm</th>\n",
       "      <th>adj_gender</th>\n",
       "      <th>task_type</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцией</td>\n",
       "      <td>grammar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую фортуну</td>\n",
       "      <td>semantics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую фортуной</td>\n",
       "      <td>semantics_grammar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>массовый</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Авторы получали подарки</td>\n",
       "      <td>2</td>\n",
       "      <td>Авторы получали районах</td>\n",
       "      <td>semantics_grammar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                               congruent  position  \\\n",
       "0            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "1            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "2            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "3            0  Автобусы проходят массовую дезинфекцию         3   \n",
       "4            2                 Авторы получали подарки         2   \n",
       "\n",
       "                                  sentence             target  \\\n",
       "0  Автобусы проходят массовую дезинфекцией            grammar   \n",
       "1       Автобусы проходят массовую фортуну          semantics   \n",
       "2      Автобусы проходят массовую фортуной  semantics_grammar   \n",
       "3   Автобусы проходят массовую дезинфекцию                 no   \n",
       "4                  Авторы получали районах  semantics_grammar   \n",
       "\n",
       "   semantics_grammar  semantics  grammar        no  unknown  ... gen_length  \\\n",
       "0                NaN        NaN      1.0       NaN      NaN  ...        NaN   \n",
       "1                NaN   1.000000      NaN       NaN      NaN  ...        NaN   \n",
       "2                1.0        NaN      NaN       NaN      NaN  ...        NaN   \n",
       "3                NaN   0.166667      NaN  0.833333      NaN  ...        NaN   \n",
       "4                1.0        NaN      NaN       NaN      NaN  ...        NaN   \n",
       "\n",
       "   gen_lemma gen_ipm  gen_gender adj_length adj_lemma    adj_ipm adj_gender  \\\n",
       "0        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "1        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "2        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "3        NaN    0.02         NaN        4.0  массовый  50.834561       masc   \n",
       "4        NaN    0.02         NaN        NaN       NaN   0.020000        NaN   \n",
       "\n",
       "     task_type selected  \n",
       "0  to_evaluate        1  \n",
       "1  to_evaluate        1  \n",
       "2  to_evaluate        1  \n",
       "3  to_evaluate        1  \n",
       "4  to_evaluate        1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['selected'] == True) & (df['task_type'] == 'to_evaluate'\n",
    "       ) & (df['percent'] >= 0.75) & (df['target'] == df['most_popular'])].drop_duplicates()\n",
    "selected_ids = []\n",
    "\n",
    "for sent_id, sent_group in df.groupby('sentence_id'):\n",
    "    if sent_group['target'].unique().shape[0] == 4:\n",
    "        selected_ids.append(sent_id)\n",
    "df = df[df['sentence_id'].isin(selected_ids)]\n",
    "df.to_csv('result/final_candidates.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92698292-d5f1-4f14-bfd4-add32a5141cb",
   "metadata": {},
   "source": [
    "- Manually check and select most appropriate stimuli for the corpus ->  \"result/FINAL_STIMULI.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ff9ab58-c6a0-4c6c-8268-a2dd9998b5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence structure</th>\n",
       "      <th>Sentence argument</th>\n",
       "      <th>Mean length</th>\n",
       "      <th>SD length</th>\n",
       "      <th>Mean IPM</th>\n",
       "      <th>SD IPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>subject</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.01</td>\n",
       "      <td>162.41</td>\n",
       "      <td>427.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>subject</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.98</td>\n",
       "      <td>102.75</td>\n",
       "      <td>136.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>subject</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>117.35</td>\n",
       "      <td>187.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>verb</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>154.37</td>\n",
       "      <td>180.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>verb</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.94</td>\n",
       "      <td>113.02</td>\n",
       "      <td>159.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>verb</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>123.96</td>\n",
       "      <td>201.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>object</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.40</td>\n",
       "      <td>94.79</td>\n",
       "      <td>87.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>object</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>120.05</td>\n",
       "      <td>168.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>object</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>129.81</td>\n",
       "      <td>209.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>gen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>gen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>gen</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.39</td>\n",
       "      <td>137.51</td>\n",
       "      <td>249.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>adj</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>141.28</td>\n",
       "      <td>277.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>adj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>adj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence structure Sentence argument  Mean length  SD length  \\\n",
       "0   Subject - Verb - Adj - Object           subject         3.20       1.01   \n",
       "1         Subject - Verb - Object           subject         3.18       0.98   \n",
       "2   Subject - Verb - Object - Gen           subject         3.60       1.28   \n",
       "3   Subject - Verb - Adj - Object              verb         3.50       0.97   \n",
       "4         Subject - Verb - Object              verb         3.64       0.94   \n",
       "5   Subject - Verb - Object - Gen              verb         3.76       0.89   \n",
       "6   Subject - Verb - Adj - Object            object         3.26       1.40   \n",
       "7         Subject - Verb - Object            object         3.30       1.20   \n",
       "8   Subject - Verb - Object - Gen            object         3.32       1.32   \n",
       "9   Subject - Verb - Adj - Object               gen          NaN        NaN   \n",
       "10        Subject - Verb - Object               gen          NaN        NaN   \n",
       "11  Subject - Verb - Object - Gen               gen         3.78       1.39   \n",
       "12  Subject - Verb - Adj - Object               adj         4.00       1.14   \n",
       "13        Subject - Verb - Object               adj          NaN        NaN   \n",
       "14  Subject - Verb - Object - Gen               adj          NaN        NaN   \n",
       "\n",
       "    Mean IPM  SD IPM  \n",
       "0     162.41  427.71  \n",
       "1     102.75  136.13  \n",
       "2     117.35  187.18  \n",
       "3     154.37  180.90  \n",
       "4     113.02  159.37  \n",
       "5     123.96  201.76  \n",
       "6      94.79   87.65  \n",
       "7     120.05  168.54  \n",
       "8     129.81  209.40  \n",
       "9       0.02    0.00  \n",
       "10      0.02    0.00  \n",
       "11    137.51  249.97  \n",
       "12    141.28  277.07  \n",
       "13      0.02    0.00  \n",
       "14      0.02    0.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('STIMULI_FINAL.csv')\n",
    "\n",
    "for_stats = df[['sentence_id','structure', 'subject_length', 'subject_ipm',\n",
    "    'verb_length', 'verb_ipm', 'object_length', 'object_ipm',\n",
    "    'gen_ipm', 'gen_length', 'adj_length', 'adj_ipm']].drop_duplicates()\n",
    "\n",
    "stats_df = []\n",
    "for arg in ['subject', 'verb', 'object', 'gen', 'adj']:\n",
    "    for struct, struct_df in for_stats.groupby('structure'):\n",
    "        stats_df.append({'Sentence structure': struct,\n",
    "                        'Sentence argument': arg,\n",
    "                        'Mean length': struct_df[f'{arg}_length'].mean(),\n",
    "                        'SD length': struct_df[f'{arg}_length'].std(),\n",
    "                        'Mean IPM': struct_df[f'{arg}_ipm'].mean(),\n",
    "                        'SD IPM': struct_df[f'{arg}_ipm'].std()})\n",
    "pd.DataFrame(stats_df).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e9041-45fd-4fe2-9d15-858c6c4570d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
